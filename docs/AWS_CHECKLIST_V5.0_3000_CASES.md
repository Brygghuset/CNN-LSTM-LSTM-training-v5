# AWS Preprocessing Checklist v5.0 - 3000 Cases Implementation

**VIKTIGT**: K√§nslig AWS-konfiguration finns i `aws_config.env` filen. 
Se denna fil f√∂r aktuella bucket-namn, S3-paths och AWS-konfigurationer.

**M√•l**: Framg√•ngsrik preprocessing av 3000 cases med full funktionalitet  
**Specifikation**: Master POC CNN-LSTM-LSTM.md  
**Baserad p√•**: Analys av fungerande (2051 cases) och misslyckade (3000 cases) k√∂rningar  
**Skapad**: 2025-10-07

---

## Executive Summary

### Kritiska Fynd fr√•n Analys
1. ‚úÖ **2051 case k√∂rning (Juli 2025)** - FUNGERADE med `pytorch_preprocessing_entry_point.py`
2. ‚ùå **200/20 case k√∂rningar (Okt 2025)** - SAG lyckade ut men skapade INGA TFRecord-filer
3. ‚ùå **3000 case k√∂rning (Okt 2025)** - Totalt misslyckande med dubbel processing + ingen output

### Root Causes
- **Software Regression**: Fungerande implementation ersatt med ofullst√§ndig version
- **Ingen Output Validation**: Success i loggar trots att inga TFRecord-filer skapades
- **Ingen Multi-Instance Distribution**: Alla instanser processar samma cases parallellt
- **Spot Instance Outestade**: F√∂rsta g√•ngen anv√§nt, checkpoint-system fungerade inte

---

## TABELL 1: Master POC Specifikation (fr√•n Master POC CNN-LSTM-LSTM.md)

| Kategori | Parameter | Specifikation | Obligatorisk | Kommentar |
|----------|-----------|---------------|--------------|-----------|
| **INPUT FEATURES** | Timeseries Features | **16 features** | ‚úÖ JA | 7 vital signs + 3 drugs + 6 ventilator |
| | Static Features | **6 features** | ‚úÖ JA | age, sex, height, weight, bmi, asa |
| | Total Input | **22 features** (16+6) | ‚úÖ JA | Enligt Master POC spec |
| **OUTPUT FEATURES** | Drug Predictions | **3 predictions** | ‚úÖ JA | Propofol, Remifentanil, Noradrenalin |
| | Ventilator Predictions | **5 predictions** | ‚úÖ JA | TV, PEEP, FIO2, RR, etSEV |
| | Total Output | **8 predictions** | ‚úÖ JA | 3 drugs + 5 ventilator |
| **NORMALIZATION** | Range | **[-1, 1]** | ‚úÖ JA | Unified normalization |
| | Method | **Unified Normalization Formula** | ‚úÖ JA | `(value - min) / (max - min) √ó 2 - 1` |
| **WINDOW** | Window Size | **300 sekunder** (5 min) | ‚úÖ JA | Sliding window |
| | Step Size | **30 sekunder** | ‚úÖ JA | 10% overlap |
| **IMPUTATION** | Method | **Smart Forward Fill** | ‚úÖ JA | Kliniska nollor + forward fill |
| | Clinical Zeros | Definierade per parameter | ‚úÖ JA | Se Master POC spec |
| **UNIT CONVERSION** | Drugs | **mg/kg/h, Œºg/kg/min** | ‚úÖ JA | Fr√•n mL/h med koncentration |
| | Tidal Volume | **ml/kg IBW** | ‚úÖ JA | Med Devine formula |
| | Pressure | **kPa, cmH2O** | ‚úÖ JA | Unit conversions |

---

## TABELL 2: Funktionalitet & B√§sta Implementation

| Funktionalitet | Prioritet | B√§sta Implementation | K√§lla Fil | Status i v5.0 | Kritiska Noter |
|----------------|-----------|---------------------|-----------|---------------|----------------|
| **CORE PROCESSING** |
| Case Range Parsing | üî¥ KRITISK | Batch + Comma-separated | `pytorch_preprocessing_entry_point.py` rad 146-193 | ‚úÖ IMPLEMENT | St√∂djer "1-3000", "1,2,3" men INTE mixed |
| Master POC Feature Mapping | üî¥ KRITISK | 16 timeseries features | `master_poc_preprocessing_entry_point.py` + orchestrator | ‚úÖ IMPLEMENT | M√ÖSTE f√∂lja Master POC spec |
| Unit Conversion | üî¥ KRITISK | Drug concentrations + IBW | `master_poc_preprocessing_orchestrator.py` | ‚úÖ IMPLEMENT | 20mg/ml Propofol, 20Œºg/ml Remifentanil |
| Smart Forward Fill | üî¥ KRITISK | Clinical zeros + forward fill | Master POC spec tabell | ‚úÖ IMPLEMENT | Olika regler per parameter |
| Unified Normalization | üî¥ KRITISK | [-1, 1] range | Master POC spec formel | ‚úÖ IMPLEMENT | Med clinical min/max ranges |
| Window Creation | üî¥ KRITISK | 300s windows, 30s step | B√•de implementations | ‚úÖ IMPLEMENT | Sliding windows |
| Static Features | üî¥ KRITISK | 6 features normalized | `pytorch_preprocessing_entry_point.py` rad 1365-1402 | ‚úÖ IMPLEMENT | age, sex, height, weight, bmi, asa |
| **OUTPUT & STORAGE** |
| TFRecord Creation | üî¥ KRITISK | Memory-efficient streaming | `pytorch_preprocessing_entry_point.py` rad 1761-1827 | ‚úÖ IMPLEMENT | SAKNAS i master_poc entry point |
| Train/Val/Test Split | üî¥ KRITISK | 70/15/15 split | `pytorch_preprocessing_entry_point.py` rad 1765-1789 | ‚úÖ IMPLEMENT | 3 separata TFRecord-filer |
| Incremental TFRecord Save | üü° HOOG | Per case eller batch | `master_poc_preprocessing_orchestrator.py` rad 398-504 | üÜï NY | Spara l√∂pande, inte vid completion |
| S3 Upload | üî¥ KRITISK | Automatisk efter completion | `pytorch_preprocessing_entry_point.py` rad 1435-1447 | ‚úÖ IMPLEMENT | M√ÖSTE ske innan timeout |
| Metadata Save | üü° HOOG | JSON med full statistik | `pytorch_preprocessing_entry_point.py` rad 1791-1804 | ‚úÖ IMPLEMENT | Lokal + S3 |
| **ROBUSTNESS** |
| Checkpoint Creation | üî¥ KRITISK | PreprocessingCheckpointManager | `checkpoint_manager.py` rad 48-361 | ‚úÖ IMPLEMENT | SAKNAS i master_poc entry point |
| Checkpoint Resume | üî¥ KRITISK | Initialize + resume logic | `pytorch_preprocessing_entry_point.py` rad 1614-1630 | ‚úÖ IMPLEMENT | Vid spot instance restart |
| Enable Checkpoints Flag | üî¥ KRITISK | `--enable-checkpoints` | B√•da entry points | ‚úÖ IMPLEMENT | M√ÖSTE s√§ttas till TRUE |
| Checkpoint Interval | üü° HOOG | Var 10-50:e case | Argument | ‚úÖ IMPLEMENT | Balans mellan overhead & safety |
| Error Handling | üü° HOOG | Try/except per case | B√•da implementations | ‚úÖ IMPLEMENT | Logga fel, forts√§tt processing |
| Memory Management | üü° HOOG | Memory-efficient batch processor | `pytorch_preprocessing_entry_point.py` rad 1093-1403 | ‚úÖ IMPLEMENT | F√∂r stora datasets |
| **MULTI-INSTANCE** |
| Case Distribution | üî¥ KRITISK | Dela cases mellan instanser | ‚ùå **SAKNAS HELT** | üÜï NY | **KRITISKT SAKNAS** |
| Host Detection | üî¥ KRITISK | SM_CURRENT_HOST env var | SageMaker environment | üÜï NY | Identifiera vilken instans |
| Host Count Detection | üî¥ KRITISK | SM_HOSTS env var | SageMaker environment | üÜï NY | Total antal instanser |
| Case Partitioning Logic | üî¥ KRITISK | Modulo eller range-based | üÜï **BEH√ñVER SKAPAS** | üÜï NY | Ex: instance_id % total_instances |
| Distributed Checkpoint | üü° HOOG | Per-instance checkpoints | üÜï **BEH√ñVER SKAPAS** | üÜï NY | S3 path med instance ID |
| **SPOT INSTANCE** |
| Spot Instance Support | üü° HOOG | `use_spot_instances=True` | Estimator config | ‚úÖ IMPLEMENT | 65-70% kostnadsbesparing |
| Max Wait Time | üü° HOOG | `max_wait = max_run * 2` | Estimator config | ‚úÖ IMPLEMENT | Flexibilitet f√∂r spot restarts |
| Spot Interrupt Handling | üî¥ KRITISK | Checkpoint + resume | Checkpoint manager | ‚úÖ IMPLEMENT | M√•ste fungera med checkpoints |
| **VALIDATION** |
| Output Verification | üî¥ KRITISK | Verifiera TFRecord-filer | üÜï **BEH√ñVER SKAPAS** | üÜï NY | Kontrollera att filer faktiskt skapas |
| S3 Verification | üî¥ KRITISK | Lista filer i S3 | üÜï **BEH√ñVER SKAPAS** | üÜï NY | Verifiera upload lyckades |
| Window Count Validation | üü° HOOG | F√∂rv√§ntat vs faktiskt | Metadata | ‚úÖ IMPLEMENT | Sanity check |
| Feature Count Validation | üü° HOOG | 16+6 input, 8 output | Pre-flight check | ‚úÖ IMPLEMENT | Verifiera spec compliance |

---

## TABELL 3: Kritiska Saknade Funktioner (M√ÖSTE Implementeras)

| Funktion | Problem | Impact | L√∂sning | Prioritet | Uppskattad Komplexitet |
|----------|---------|--------|---------|-----------|------------------------|
| **Multi-Instance Case Distribution** | Alla instanser processar SAMMA cases | 6x redundant arbete, konflikt vid S3 upload | Implementera case partitioning baserat p√• `SM_CURRENT_HOST` och `SM_HOSTS` | üî¥ KRITISK | üü¢ L√ÖG (50 rader kod) |
| **Incremental TFRecord Save** | Data sparas endast vid completion | ALL data f√∂rloras vid timeout | Spara TFRecord l√∂pande per batch eller case | üî¥ KRITISK | üü° MEDEL (100 rader kod) |
| **Enable Checkpoints Default** | Checkpoints aldrig aktiverade | Ingen resume m√∂jlighet | S√§tt `default=True` eller inkludera i starter script | üî¥ KRITISK | üü¢ L√ÖG (1 rad kod) |
| **TFRecord Integration i Master POC** | Entry point sparar INTE TFRecord | Ingen output fr√•n processing | Integrera `create_memory_efficient_tfrecord()` | üî¥ KRITISK | üü° MEDEL (150 rader kod) |
| **Output Verification** | Ingen validering att filer skapades | False positives i success loggar | L√§gg till S3 list + count check | üî¥ KRITISK | üü¢ L√ÖG (30 rader kod) |
| **Distributed Checkpoint Paths** | Alla instanser skriver till samma checkpoint | Konflikt och corruption | Unik checkpoint path per instance | üü° HOOG | üü¢ L√ÖG (20 rader kod) |
| **Spot Interrupt Testing** | Aldrig testat med spot instances | Ok√§nda failure modes | Testk√∂ring med spot + manuell interrupt | üü° HOOG | üü° MEDEL (test k√∂rning) |
| **Train/Val/Test Split Logic** | Saknas i master_poc entry point | Ingen split av data | Kopiera fr√•n pytorch_preprocessing | üî¥ KRITISK | üü¢ L√ÖG (30 rader kod) |
| **Robust Case Format Parsing** | St√∂djer inte blandat format "1-10,17,0022" | Begr√§nsad flexibilitet i case selection | Ut√∂ka parse_case_range() med mixed format support | üî¥ KRITISK | üü¢ L√ÖG (40 rader kod) |
| **Graceful Shutdown Handling** | Ingen SIGTERM hantering vid timeout | Data f√∂rloras vid MaxRuntimeExceeded | Implementera signal handler f√∂r graceful shutdown | üî¥ KRITISK | üü° MEDEL (80 rader kod) |
| **S3 Retry Logic** | Inga retries vid S3 failures | Spot instance restarts kan orsaka S3 fel | Exponential backoff f√∂r alla S3 operations | üî¥ KRITISK | üü° MEDEL (60 rader kod) |
| **Idempotent S3 Writes** | √Öterk√∂rningar kan skapa dubletter | Konflikt vid multiple runs | Overwrite policy eller unique job_id suffix | üü° HOOG | üü¢ L√ÖG (20 rader kod) |

---

## TABELL 4: AWS SageMaker Configuration f√∂r 3000 Cases

| Parameter | V√§rde | K√§lla | Motivering | Validering |
|-----------|-------|-------|------------|------------|
| **ESTIMATOR CONFIG** |
| Entry Point | `master_poc_preprocessing_v5.py` | üÜï NY FIL | Kombinerar Master POC spec + fungerande funktioner | M√•ste skapas |
| Source Dir | `src/` | Standard | All k√§llkod i src/ | Befintlig struktur |
| Framework Version | `1.12.1` | AWS Guide v4.1 | PyTorch framework | Testad |
| Python Version | `py38` | AWS Guide v4.1 | Python 3.8 | Testad |
| Instance Type | `ml.m5.2xlarge` | Guide v4.1 + Master POC | 8 vCPU, 32GB RAM | Adequate f√∂r processing |
| Instance Count | `6` | Master POC Instruction v1.1 | Parallellisering | **KR√ÑVER case distribution** |
| Use Spot Instances | `True` | Master POC Instruction v1.1 | 65-70% kostnadsbesparing | Testat (men failed) |
| Max Run | `93600s` (26h) | Uppskattning | 3000 cases √ó ~30s/case / 6 inst | Konservativ uppskattning |
| Max Wait | `187200s` (52h) | `max_run √ó 2` | Spot flexibilitet | Master POC Instruction |
| **HYPERPARAMETERS** |
| Cases | `1-3000` | Requirement | Full dataset | Standard format |
| Batch Size | `50` | Balans memory/checkpoint | Checkpoint var 50:e case | Testad |
| Checkpoint Interval | `50` | Balans overhead/safety | Var 50:e case | Master POC Instruction |
| **Enable Checkpoints** | `True` | üÜï **√ÑNDRING** | **M√ÖSTE vara True** | **Kritisk √§ndring** |
| Window Size | `300` | Master POC spec | 5 minuters f√∂nster | Specifikation |
| Step Size | `30` | Master POC spec | 30 sekunders steg | Specifikation |
| Timeseries Features | `16` | Master POC spec | **INTE 14** | Specifikation |
| Static Features | `6` | Master POC spec | age, sex, height, weight, bmi, asa | Specifikation |
| Output Features | `8` | Master POC spec | **INTE 7** | Specifikation |
| Normalization Range | `-1.0 1.0` | Master POC spec | Mellanslag, INTE komma | Specifikation |
| Imputation Method | `master_poc_smart_forward_fill` | Master POC spec | Clinical zeros + forward fill | Specifikation |
| Pipeline Type | `master_poc` | Identifier | Master POC pipeline | Standard |
| S3 Bucket | [Se `S3_PRIMARY_BUCKET` i `aws_config.env`] | Master POC Instruction | Data storage | Befintlig bucket |
| **S3 PATHS** |
| Input Data | [Se `S3_INPUT_PATH` i `aws_config.env`] | Master POC Instruction | VitalDB data | Befintlig |
| Output Path | [Se `S3_OUTPUT_PATH` i `aws_config.env`] | Master POC Instruction | TFRecord output | Befintlig |
| Checkpoint Path | [Se `S3_CHECKPOINT_PATH` i `aws_config.env`] | üÜï NY | Checkpoint storage | Beh√∂ver skapas |

---

## TABELL 5: Implementation Plan

| Steg | Task | Beskrivning | Beroenden | Uppskattad Tid | Prioritet |
|------|------|-------------|-----------|----------------|-----------|
| **FAS 1: KRITISKA FIXES** |
| 1.1 | Skapa ny entry point | `master_poc_preprocessing_v5.py` kombinerar b√•da implementations | Ingen | 4 timmar | üî¥ KRITISK |
| 1.2 | Implementera case distribution | Dela cases mellan instanser med SM_CURRENT_HOST | 1.1 | 2 timmar | üî¥ KRITISK |
| 1.3 | Integrera TFRecord creation | Kopiera fr√•n pytorch_preprocessing | 1.1 | 2 timmar | üî¥ KRITISK |
| 1.4 | Integrera checkpoint manager | Kopiera fr√•n pytorch_preprocessing | 1.1 | 2 timmar | üî¥ KRITISK |
| 1.5 | Implementera incremental save | TFRecord save per batch | 1.3, 1.4 | 3 timmar | üî¥ KRITISK |
| 1.6 | Enable checkpoints default | S√§tt default=True | 1.4 | 5 minuter | üî¥ KRITISK |
| 1.7 | L√§gg till output verification | S3 list + count check | 1.3 | 1 timme | üî¥ KRITISK |
| **FAS 2: TESTER** |
| 2.1 | Test case distribution | K√∂r 10 cases med 2 instanser | 1.2 | 30 minuter | üî¥ KRITISK |
| 2.2 | Test checkpoint resume | Avbryt + resume test | 1.4 | 30 minuter | üî¥ KRITISK |
| 2.3 | Test incremental save | Verifiera TFRecord skapas l√∂pande | 1.5 | 30 minuter | üî¥ KRITISK |
| 2.4 | Test spot instance | 50 cases med spot + manuell interrupt | 1.4, 1.6 | 1 timme | üü° HOOG |
| 2.5 | Test full pipeline | 100 cases med alla features | Alla ovan | 1 timme | üü° HOOG |
| **FAS 3: SM√ÖSKALIG PILOT** |
| 3.1 | Pilot 200 cases | Verifiera med 200 cases, 2 instanser | Fas 1-2 | 2 timmar | üü° HOOG |
| 3.2 | Verifiera output | Kontrollera TFRecord-filer i S3 | 3.1 | 30 minuter | üü° HOOG |
| 3.3 | Analysera metadata | Verifiera windows, features, split | 3.1 | 30 minuter | üü° HOOG |
| **FAS 4: FULLSKALIG K√ñRNING** |
| 4.1 | 3000 case preprocessing | Full k√∂rning med 6 instanser, spot | Fas 1-3 | 26 timmar | üü¢ M√ÖLET |
| 4.2 | √ñvervaka progress | CloudWatch monitoring | 4.1 | Kontinuerlig | üü¢ M√ÖLET |
| 4.3 | Verifiera completion | Kontrollera alla TFRecord-filer | 4.1 | 1 timme | üü¢ M√ÖLET |
| 4.4 | Uppdatera dokumentation | Dokumentera v5.0 implementation | 4.3 | 2 timmar | üü¢ M√ÖLET |

**Total Uppskattad Tid**: 
- Fas 1-2: ~15 timmar development + testing
- Fas 3: ~3 timmar pilot
- Fas 4: ~26 timmar k√∂rning + 3 timmar verifiering

---

## TABELL 6: Code Snippets - Multi-Instance Distribution

### Implementation av Case Distribution (NYA FUNKTIONER)

```python
# I master_poc_preprocessing_v5.py

import os
import json

def get_sagemaker_host_info():
    """H√§mta SageMaker host information fr√•n environment variables."""
    training_env = json.loads(os.environ.get('SM_TRAINING_ENV', '{}'))
    
    current_host = training_env.get('current_host', 'algo-1')
    all_hosts = training_env.get('hosts', ['algo-1'])
    host_index = all_hosts.index(current_host)
    total_hosts = len(all_hosts)
    
    logger.info(f"üñ•Ô∏è SageMaker Host Info:")
    logger.info(f"   Current Host: {current_host} (index {host_index})")
    logger.info(f"   Total Hosts: {total_hosts}")
    logger.info(f"   All Hosts: {all_hosts}")
    
    return {
        'current_host': current_host,
        'host_index': host_index,
        'total_hosts': total_hosts,
        'all_hosts': all_hosts
    }

def distribute_cases_across_instances(case_ids: List[str], host_info: dict) -> List[str]:
    """
    Dela upp cases mellan instanser f√∂r att undvika dubbel processing.
    
    Anv√§nder modulo f√∂r j√§mn f√∂rdelning:
    - Instance 0 f√•r case 0, 6, 12, 18, ...
    - Instance 1 f√•r case 1, 7, 13, 19, ...
    - Instance 2 f√•r case 2, 8, 14, 20, ...
    etc.
    """
    host_index = host_info['host_index']
    total_hosts = host_info['total_hosts']
    
    # Filtrera cases f√∂r denna instans
    instance_cases = [
        case_id for i, case_id in enumerate(case_ids)
        if i % total_hosts == host_index
    ]
    
    logger.info(f"üìä Case Distribution:")
    logger.info(f"   Total Cases: {len(case_ids)}")
    logger.info(f"   This Instance Cases: {len(instance_cases)}")
    logger.info(f"   First 5: {instance_cases[:5]}")
    logger.info(f"   Last 5: {instance_cases[-5:]}")
    
    return instance_cases

def create_distributed_checkpoint_path(base_path: str, host_info: dict) -> str:
    """Skapa unik checkpoint path f√∂r varje instans."""
    current_host = host_info['current_host']
    checkpoint_path = f"{base_path}/{current_host}"
    
    logger.info(f"üíæ Checkpoint Path: {checkpoint_path}")
    return checkpoint_path

# Anv√§ndning i main():
def main():
    args = parse_args()
    
    # H√§mta host info
    host_info = get_sagemaker_host_info()
    
    # Parse alla cases
    all_case_ids = parse_case_range(args.cases)
    
    # Distribuera cases till denna instans
    instance_cases = distribute_cases_across_instances(all_case_ids, host_info)
    
    # Skapa instans-specifik checkpoint path
    checkpoint_path = create_distributed_checkpoint_path(
        args.checkpoint_base_path,
        host_info
    )
    
    # Processa endast denna instans cases
    process_cases(instance_cases, checkpoint_path, args)
```

---

## TABELL 7: Verifierings-Checklista (Efter K√∂rning)

| Verifiering | Kommando/Metod | F√∂rv√§ntat Resultat | Kritiskt? |
|-------------|----------------|-------------------|-----------|
| **S3 OUTPUT** |
| TFRecord-filer skapade | `aws s3 ls s3://master-poc-v1.0/processed-data/master-poc-pipeline/ --recursive` | 3 filer: train.tfrecord, validation.tfrecord, test.tfrecord | ‚úÖ JA |
| TFRecord-storlek | `aws s3 ls s3://... --human-readable` | >100MB per fil (beroende p√• cases) | ‚úÖ JA |
| Metadata fil | `aws s3 ls ...preprocessing_metadata.json` | 1 fil med statistik | ‚úÖ JA |
| **METADATA INNEH√ÖLL** |
| Total samples | L√§s JSON: `total_samples` | >100,000 windows (beroende p√• cases) | ‚úÖ JA |
| Train/val/test split | L√§s JSON: `train_samples`, `validation_samples`, `test_samples` | 70/15/15 split | ‚úÖ JA |
| Window shape | L√§s JSON: `window_shape` | [300, 16] | ‚úÖ JA |
| Target shape | L√§s JSON: `target_shape` | [8] | ‚úÖ JA |
| Static shape | L√§s JSON: `static_features_shape` | [6] | ‚úÖ JA |
| Success rate | L√§s JSON: `success_rate` | >95% | ‚ö†Ô∏è √ñNSKV√ÑRT |
| **CHECKPOINT** |
| Checkpoint-filer | `aws s3 ls s3://master-poc-v1.0/checkpoints/master-poc-v5-3000cases/ --recursive` | 6 filer (en per instans) | ‚ö†Ô∏è VID SPOT |
| Checkpoint state | L√§s checkpoint JSON | processed_cases, failed_cases lists | ‚ö†Ô∏è VID SPOT |
| **LOGS** |
| CloudWatch loggar | AWS Console eller CLI | Success meddelanden, inga errors | ‚úÖ JA |
| Processing time | CloudWatch metrics | ~26 timmar total | ‚ö†Ô∏è UPPSKATTNING |
| Cost | AWS Cost Explorer | ~$12-15 med spot instances | ‚ö†Ô∏è INFO |
| **FUNKTIONALITET** |
| Case distribution | S√∂k i loggar: "This Instance Cases" | Olika antal per instans | ‚úÖ JA |
| No double processing | Verifiera case overlap mellan instanser | Ingen overlap | ‚úÖ JA |
| Checkpoint saves | S√∂k i loggar: "Checkpoint saved" | Var 50:e case | ‚ö†Ô∏è VID SPOT |
| TFRecord saves | S√∂k i loggar: "TFRecord files created" | Vid completion | ‚úÖ JA |

---

## TABELL 8: Risk Assessment & Mitigation

| Risk | Sannolikhet | Impact | Mitigation | Contingency Plan |
|------|-------------|--------|------------|------------------|
| **Spot Instance Interrupt** | üü° MEDEL | üü° MEDEL | Checkpoint var 50:e case + max_wait 52h | Resume fr√•n checkpoint automatiskt |
| **Timeout (26h inte tillr√§ckligt)** | üü° MEDEL | üî¥ HOOG | Incremental save + konservativ tid-uppskattning | F√∂rl√§ng max_run till 36h |
| **Instance case overlap** | üî¥ HOOG (om ej fixat) | üî¥ KRITISK | Case distribution implementation | K√∂r endast 1 instans som fallback |
| **TFRecord corruption** | üü¢ L√ÖG | üî¥ HOOG | Validera efter varje save | Checkpoint resume + reprocess |
| **S3 upload failure** | üü¢ L√ÖG | üî¥ HOOG | Retry logic + verification | Manuell upload fr√•n checkpoint |
| **Memory overflow** | üü° MEDEL | üü° MEDEL | Memory-efficient batch processor + batch size 50 | Minska batch size till 25 |
| **Feature mapping fel** | üü¢ L√ÖG | üî¥ KRITISK | Pre-flight validation + unit tests | Debugga + rerun med fix |
| **Cost overrun** | üü¢ L√ÖG | üü° MEDEL | Spot instances (-70%) + monitoring | Avbryt jobb om kostnad >$20 |

---

## SAMMANFATTNING: Kritiska √Ñndringar fr√•n Tidigare

### ‚úÖ Fungerande (Beh√•ll fr√•n 2051 case k√∂rning)
- `pytorch_preprocessing_entry_point.py` structure
- TFRecord creation med train/val/test split
- Checkpoint manager integration
- Memory-efficient processing
- S3 upload automation

### ‚úÖ Fungerande (Beh√•ll fr√•n Master POC)
- 16+6 features (INTE 14+6)
- 8 outputs (INTE 7)
- Master POC unit conversion
- Smart forward fill med clinical zeros
- Unified normalization [-1, 1]

### üÜï NYA Implementationer (KRITISKA)
1. **Multi-Instance Case Distribution** - Dela cases mellan 6 instanser
2. **Incremental TFRecord Save** - Spara l√∂pande, inte vid completion
3. **Enable Checkpoints Default** - S√§tt till True
4. **Output Verification** - Verifiera att filer faktiskt skapas
5. **Distributed Checkpoint Paths** - Unika paths per instans

### ‚ùå TA BORT (Fr√•n tidigare k√∂rningar)
- ‚ùå Single-instance assumption
- ‚ùå Bulk save endast vid completion
- ‚ùå Checkpoint disabled by default
- ‚ùå Ingen output validation

---

## N√ÑSTA STEG

1. **Skapa ny entry point**: `master_poc_preprocessing_v5.py`
2. **Implementera case distribution**: Kod snippets ovan
3. **Test med 10 cases, 2 instanser**: Verifiera distribution
4. **Test checkpoint resume**: Manuell interrupt + resume
5. **Pilot 200 cases**: Full validation
6. **3000 cases production run**: Med monitoring

**Estimerat: 2-3 dagars utveckling + tester innan production k√∂rning**

---

**Version**: 5.0  
**Skapad**: 2025-10-07  
**Status**: Redo f√∂r implementation  
**Next Review**: Efter pilot 200 cases

